{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning (INFR11211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we work with a spam filtering dataset. We will learn how to perform classification tasks using Naive Bayes and Logistic Regression. For this, we will use the the packages introduced in Lab 0, and `scikit-learn` package (`sklearn`): a machine learning library for Python which works with numpy array, and pandas DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note**: Throughout this lab we make reference to [`methods`](https://en.wikipedia.org/wiki/Method_%28computer_programming%29) for specific objects e.g. \"make use of the predict method of the MultinomialNB classifier\". If you get confused, refer to the documentation and just ctrl+f for the object concerned:\n",
    "* [Scikit-learn API documentation](https://scikit-learn.org/stable/modules/classes.html) \n",
    "* [Seaborn API documentation](https://seaborn.github.io/api.html)\n",
    "* [Matplotlib Pyplot documentation](https://matplotlib.org/stable/api/pyplot_summary.html)\n",
    "* [Pandas API documentation](https://pandas.pydata.org/pandas-docs/version/1.5.3/reference/index.html)\n",
    "* [Numpy documentation](https://numpy.org/doc/stable/)\n",
    "\n",
    "There are also tonnes of great examples online; googling key words with the word \"example\" will serve you well. However, note that sometimes examples online will use different version of the packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the packages (run all the code cells as you read along):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Clarification*:\n",
    "\n",
    "* The `%matplotlib inline` command is a special ipython [built in magic command](http://ipython.readthedocs.io/en/stable/interactive/magics.html) which forces the matplotlib plots to be rendered within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spambase dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Spambase](http://archive.ics.uci.edu/ml/datasets/Spambase) classification dataset consists of tagged emails from a single email account. You should read through the description available for this data to get a feel for what you're dealing with. We have downloaded the dataset for you.\n",
    "\n",
    "You will find the dataset located at `./datasets/spambase.csv` (the `datasets` directory is adjacent to this file). Execute the cell below to load the csv into in a pandas DataFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'spambase.csv')\n",
    "spambase = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded the data. Let's get a feeling of what the data looks like by using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                        61.0   \n",
       "1                       5.114                       101.0   \n",
       "2                       9.821                       485.0   \n",
       "3                       3.537                        40.0   \n",
       "4                       3.537                        40.0   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                     278.0      1.0  \n",
       "1                    1028.0      1.0  \n",
       "2                    2259.0      1.0  \n",
       "3                     191.0      1.0  \n",
       "4                     191.0      1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.head(5) # Display the 5 first rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Display the number of features in the dataset (i.e. number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(len(spambase.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Display the number of observations (i.e. number of rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266858\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(spambase.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the mean and standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_freq_make</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.305358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_address</th>\n",
       "      <td>0.213015</td>\n",
       "      <td>1.290575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_all</th>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.504143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_3d</th>\n",
       "      <td>0.065425</td>\n",
       "      <td>1.395151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_our</th>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.672513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_over</th>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.273824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_remove</th>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.391441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_internet</th>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.401071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_order</th>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.278616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_mail</th>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.644755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_receive</th>\n",
       "      <td>0.059824</td>\n",
       "      <td>0.201545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_will</th>\n",
       "      <td>0.541702</td>\n",
       "      <td>0.861698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_people</th>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.301036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_report</th>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.335184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_addresses</th>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.258843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_free</th>\n",
       "      <td>0.248848</td>\n",
       "      <td>0.825792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_business</th>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.444055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_email</th>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.531122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_you</th>\n",
       "      <td>1.662100</td>\n",
       "      <td>1.775481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_credit</th>\n",
       "      <td>0.085577</td>\n",
       "      <td>0.509767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_your</th>\n",
       "      <td>0.809761</td>\n",
       "      <td>1.200810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_font</th>\n",
       "      <td>0.121202</td>\n",
       "      <td>1.025756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_000</th>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.350286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_money</th>\n",
       "      <td>0.094269</td>\n",
       "      <td>0.442636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_hp</th>\n",
       "      <td>0.549504</td>\n",
       "      <td>1.671349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_hpl</th>\n",
       "      <td>0.265384</td>\n",
       "      <td>0.886955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_george</th>\n",
       "      <td>0.767305</td>\n",
       "      <td>3.367292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_650</th>\n",
       "      <td>0.124845</td>\n",
       "      <td>0.538576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_lab</th>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.593327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_labs</th>\n",
       "      <td>0.102852</td>\n",
       "      <td>0.456682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_telnet</th>\n",
       "      <td>0.064753</td>\n",
       "      <td>0.403393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_857</th>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.328559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_data</th>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.555907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_415</th>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.329445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_85</th>\n",
       "      <td>0.105412</td>\n",
       "      <td>0.532260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_technology</th>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.402623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_1999</th>\n",
       "      <td>0.136953</td>\n",
       "      <td>0.423451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_parts</th>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.220651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_pm</th>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.434672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_direct</th>\n",
       "      <td>0.064834</td>\n",
       "      <td>0.349916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_cs</th>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.361205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_meeting</th>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.766819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_original</th>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.223812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_project</th>\n",
       "      <td>0.079196</td>\n",
       "      <td>0.621976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_re</th>\n",
       "      <td>0.301224</td>\n",
       "      <td>1.011687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_edu</th>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.911119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_table</th>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.076274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_conference</th>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.285735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_;</th>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.243471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_(</th>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.270355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_[</th>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.109394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_!</th>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.815672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_$</th>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.245882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_#</th>\n",
       "      <td>0.044238</td>\n",
       "      <td>0.429342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <td>5.191515</td>\n",
       "      <td>31.729449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <td>52.172789</td>\n",
       "      <td>194.891310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <td>283.289285</td>\n",
       "      <td>606.347851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_spam</th>\n",
       "      <td>0.394045</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean         std\n",
       "word_freq_make                0.104553    0.305358\n",
       "word_freq_address             0.213015    1.290575\n",
       "word_freq_all                 0.280656    0.504143\n",
       "word_freq_3d                  0.065425    1.395151\n",
       "word_freq_our                 0.312223    0.672513\n",
       "word_freq_over                0.095901    0.273824\n",
       "word_freq_remove              0.114208    0.391441\n",
       "word_freq_internet            0.105295    0.401071\n",
       "word_freq_order               0.090067    0.278616\n",
       "word_freq_mail                0.239413    0.644755\n",
       "word_freq_receive             0.059824    0.201545\n",
       "word_freq_will                0.541702    0.861698\n",
       "word_freq_people              0.093930    0.301036\n",
       "word_freq_report              0.058626    0.335184\n",
       "word_freq_addresses           0.049205    0.258843\n",
       "word_freq_free                0.248848    0.825792\n",
       "word_freq_business            0.142586    0.444055\n",
       "word_freq_email               0.184745    0.531122\n",
       "word_freq_you                 1.662100    1.775481\n",
       "word_freq_credit              0.085577    0.509767\n",
       "word_freq_your                0.809761    1.200810\n",
       "word_freq_font                0.121202    1.025756\n",
       "word_freq_000                 0.101645    0.350286\n",
       "word_freq_money               0.094269    0.442636\n",
       "word_freq_hp                  0.549504    1.671349\n",
       "word_freq_hpl                 0.265384    0.886955\n",
       "word_freq_george              0.767305    3.367292\n",
       "word_freq_650                 0.124845    0.538576\n",
       "word_freq_lab                 0.098915    0.593327\n",
       "word_freq_labs                0.102852    0.456682\n",
       "word_freq_telnet              0.064753    0.403393\n",
       "word_freq_857                 0.047048    0.328559\n",
       "word_freq_data                0.097229    0.555907\n",
       "word_freq_415                 0.047835    0.329445\n",
       "word_freq_85                  0.105412    0.532260\n",
       "word_freq_technology          0.097477    0.402623\n",
       "word_freq_1999                0.136953    0.423451\n",
       "word_freq_parts               0.013201    0.220651\n",
       "word_freq_pm                  0.078629    0.434672\n",
       "word_freq_direct              0.064834    0.349916\n",
       "word_freq_cs                  0.043667    0.361205\n",
       "word_freq_meeting             0.132339    0.766819\n",
       "word_freq_original            0.046099    0.223812\n",
       "word_freq_project             0.079196    0.621976\n",
       "word_freq_re                  0.301224    1.011687\n",
       "word_freq_edu                 0.179824    0.911119\n",
       "word_freq_table               0.005444    0.076274\n",
       "word_freq_conference          0.031869    0.285735\n",
       "char_freq_;                   0.038575    0.243471\n",
       "char_freq_(                   0.139030    0.270355\n",
       "char_freq_[                   0.016976    0.109394\n",
       "char_freq_!                   0.269071    0.815672\n",
       "char_freq_$                   0.075811    0.245882\n",
       "char_freq_#                   0.044238    0.429342\n",
       "capital_run_length_average    5.191515   31.729449\n",
       "capital_run_length_longest   52.172789  194.891310\n",
       "capital_run_length_total    283.289285  606.347851\n",
       "is_spam                       0.394045    0.488698"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "spambase.agg(['mean', 'std']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to *remove* some of the features from our data. There are various reasons for wanting to do so, for instance we might think that these are not relevant to the task we want to perform (i.e. e-mail classification) or they might have been contaminated with noise during the data collection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Delete the `capital_run_length_average`, `capital_run_length_longest`, and  `capital_run_length_total` features. \n",
    "*Hint*: You should make use of the [`drop`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) method. \n",
    "\n",
    "*Tip*: some pandas methods have the argument `inplace` which you can use to determine whether they alter the object they are called upon and return nothing, or return a new object. This is particularly useful if you are dealing with huge datasets where you would typically want to operate `inplace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student needs to provide code similar to below\n",
    "spambase.drop([\"capital_run_length_average\", \"capital_run_length_longest\", \n",
    "                          \"capital_run_length_total\"], axis=1, inplace=True)\n",
    "## or, less efficiently\n",
    "# spambase = spambase.drop([\"capital_run_length_average\", \"capital_run_length_longest\", \n",
    "#                           \"capital_run_length_total\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Display the new number of features. Does it look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(len(spambase.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining features represent relative frequencies of various important words and characters in emails. This is true for all features except `is_spam` which represents whether the e-mail was annotated as spam or not. So each e-mail is represented by a 55 dimensional vector representing whether or not a particular word exists in an e-mail. This is the so called [bag of words](http://en.wikipedia.org/wiki/Bag_of_words_model) representation and is clearly a very crude approximation since it does not take into account the order of the words in the emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3  ==========\n",
    "Now we want to simplify the problem by transforming our dataset. We will replace all numerical values which represent word frequencies with a binary value representing whether each word was present in a document or not.\n",
    "\n",
    "**a)** Crate a new dataframe called `spambase_binary` from `spambase`. *Hint*: Look into the [`copy`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.copy.html?highlight=copy#pandas.DataFrame.copy) method in pandas. \n",
    "\n",
    "*Tip*: Be careful, in python, unless you explictly say not to, assigment is typically just reference e.g.\n",
    "```python\n",
    "i = [1, 3]\n",
    "j = i\n",
    "i[1] = 5\n",
    "print(j)\n",
    "```\n",
    "outputs:\n",
    "```\n",
    "[1, 5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "spambase_binary = spambase.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Convert all features in `spambase_binary` to Boolean values: 1 if the word or character is present in the email, or 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_1664\\4287125244.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  spambase_binary.applymap(lambda x: 1 if x > 0 else 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0                  0                  1              1             0   \n",
       "1                  1                  1              1             0   \n",
       "2                  1                  0              1             0   \n",
       "3                  0                  0              0             0   \n",
       "4                  0                  0              0             0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596               1                  0              1             0   \n",
       "4597               0                  0              0             0   \n",
       "4598               1                  0              1             0   \n",
       "4599               1                  0              0             0   \n",
       "4600               0                  0              1             0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0                 1               0                 0                   0   \n",
       "1                 1               1                 1                   1   \n",
       "2                 1               1                 1                   1   \n",
       "3                 1               0                 1                   1   \n",
       "4                 1               0                 1                   1   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596              0               1                 0                   0   \n",
       "4597              0               0                 0                   0   \n",
       "4598              0               0                 0                   0   \n",
       "4599              1               0                 0                   0   \n",
       "4600              0               0                 0                   0   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "0                   0               0  ...              0                0   \n",
       "1                   0               1  ...              0                0   \n",
       "2                   1               1  ...              1                0   \n",
       "3                   1               1  ...              0                0   \n",
       "4                   1               1  ...              0                0   \n",
       "...               ...             ...  ...            ...              ...   \n",
       "4596                0               0  ...              1                0   \n",
       "4597                0               0  ...              1                0   \n",
       "4598                0               0  ...              1                0   \n",
       "4599                0               0  ...              1                0   \n",
       "4600                0               0  ...              1                0   \n",
       "\n",
       "      word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
       "0                        0            0            0            0   \n",
       "1                        0            0            1            0   \n",
       "2                        0            1            1            0   \n",
       "3                        0            0            1            0   \n",
       "4                        0            0            1            0   \n",
       "...                    ...          ...          ...          ...   \n",
       "4596                     0            0            1            0   \n",
       "4597                     0            0            0            0   \n",
       "4598                     0            1            1            0   \n",
       "4599                     0            0            1            0   \n",
       "4600                     0            0            0            0   \n",
       "\n",
       "      char_freq_!  char_freq_$  char_freq_#  is_spam  \n",
       "0               1            0            0        1  \n",
       "1               1            1            1        1  \n",
       "2               1            1            1        1  \n",
       "3               1            0            0        1  \n",
       "4               1            0            0        1  \n",
       "...           ...          ...          ...      ...  \n",
       "4596            0            0            0        0  \n",
       "4597            1            0            0        0  \n",
       "4598            0            0            0        0  \n",
       "4599            0            0            0        0  \n",
       "4600            1            0            0        0  \n",
       "\n",
       "[4601 rows x 55 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "spambase_binary.applymap(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the 5 last observations of the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "4596            0.31                0.0           0.62           0.0   \n",
      "4597            0.00                0.0           0.00           0.0   \n",
      "4598            0.30                0.0           0.30           0.0   \n",
      "4599            0.96                0.0           0.00           0.0   \n",
      "4600            0.00                0.0           0.65           0.0   \n",
      "\n",
      "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "4596           0.00            0.31               0.0                 0.0   \n",
      "4597           0.00            0.00               0.0                 0.0   \n",
      "4598           0.00            0.00               0.0                 0.0   \n",
      "4599           0.32            0.00               0.0                 0.0   \n",
      "4600           0.00            0.00               0.0                 0.0   \n",
      "\n",
      "      word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
      "4596              0.0             0.0  ...           0.31              0.0   \n",
      "4597              0.0             0.0  ...           2.00              0.0   \n",
      "4598              0.0             0.0  ...           1.20              0.0   \n",
      "4599              0.0             0.0  ...           0.32              0.0   \n",
      "4600              0.0             0.0  ...           0.65              0.0   \n",
      "\n",
      "      word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
      "4596                   0.0        0.000        0.232          0.0   \n",
      "4597                   0.0        0.000        0.000          0.0   \n",
      "4598                   0.0        0.102        0.718          0.0   \n",
      "4599                   0.0        0.000        0.057          0.0   \n",
      "4600                   0.0        0.000        0.000          0.0   \n",
      "\n",
      "      char_freq_!  char_freq_$  char_freq_#  is_spam  \n",
      "4596        0.000          0.0          0.0      0.0  \n",
      "4597        0.353          0.0          0.0      0.0  \n",
      "4598        0.000          0.0          0.0      0.0  \n",
      "4599        0.000          0.0          0.0      0.0  \n",
      "4600        0.125          0.0          0.0      0.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(spambase_binary.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the transformed dataset, we now wish to train a NaÃ¯ve Bayes classifier to distinguish spam from regular email by fitting a distribution of the number of occurrences of each word for all the spam and non-spam e-mails. Read about the [Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and the underlying assumption if you are not already familiar with it from the lectures. In this lab we focus on the [Multinomial Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes). \n",
    "\n",
    "We will make use of the `MultinomialNB` class in `sklearn`. **Check out the user guide [description](https://scikit-learn.org/stable/modules/naive_bayes.html?highlight=multinomialnb#multinomial-naive-bayes) and [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB) to familiarise yourself with this class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All classifiers in `sklearn` implement a `fit()` and `predict()` [method](https://en.wikipedia.org/wiki/Method_%28computer_programming%29). The first learns the parameters of the model and the latter classifies inputs. For a Naive Bayes classifier, the [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB.fit) method takes at least two input arguments `X` and `y`, where `X` are the input features and `y` are the labels associated with each example in the training dataset (i.e. targets). \n",
    "\n",
    "As a first step we extract the input features and targets from the DataFrame. To do so, we will use the [`values`](https://pandas.pydata.org/pandas-docs/version/1.3.1/reference/api/pandas.DataFrame.values.html) property. For the input features we want to select all columns except `is_spam` and for this we may use the [`drop`](https://pandas.pydata.org/pandas-docs/version/1.3.1/reference/api/pandas.DataFrame.drop.html) method which discards the specified columns along the given axis. In fact, we can combine these two operations in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 4 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Create a Pandas DataFrame object `X` containing only the features (i.e. exclude the label `is_spam`). We need to do this as it is the input Scikit-learn objects expect for fitting. These will be our training features. *Hint*: make use of the `drop` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "X = spambase_binary.drop('is_spam', axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Create a Pandas Series object `y` that contains only the label from `spambase_binary`. These will be our training class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "Y = spambase_binary['is_spam'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the dimensionality (i.e. `shape`) of each of the two arrays. *Hint:* The shape of `X` and `y` should be `(4601, 54)` and `(4601,)` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 54)\n",
      "(4601,)\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Display the count of the number of emails that are spam (i.e. where `y == 1`), and those that are not spam (i.e. where `y == 0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam count: 1813\n",
      "non-spam count: 2788\n"
     ]
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "print(\"spam count:\" ,  np.sum(Y == 1))\n",
    "print(\"non-spam count:\" , np.sum(Y == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 5 ==========\n",
    "\n",
    "Now we want to train a Multinomial Naive Bayes classifier. Initialise a `MultinomialNB` object and [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB.fit) the classifier using the `X` and `y` arrays extracted in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "MultinomialNB_model = MultinomialNB()\n",
    "MultinomialNB_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the classifier by looking at the classification accuracy on the data. \n",
    "\n",
    "Scikit-learn model objects have built in scoring methods. The default [`score` method for `MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb+score#sklearn.naive_bayes.MultinomialNB.score) estimates the classification accuracy score. Alternatively, you can compute the prediction for the training data and make use of the [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score) function (that is in fact what the classifier's `score()` method does under the hood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 6 ========== "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Display the log-prior probabilities for each class. *Hint:* use tab-completion to figure out which feature of the `MultinomialNB` structure you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.95399423e+00, -7.08017803e-03],\n",
       "       [-1.03709914e+01, -3.13287076e-05],\n",
       "       [-1.61321821e+01, -9.86012338e-08],\n",
       "       ...,\n",
       "       [-1.23494348e-01, -2.15267169e+00],\n",
       "       [-5.76123192e-01, -8.25703501e-01],\n",
       "       [-3.11236681e-01, -1.31878704e+00]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code goes here:\n",
    "MultinomialNB_model.predict_log_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Extract the predictions from your classifier using the training data as input. *Hint*: make use of the `predict` method of the `MultinomialNB` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "Pred = MultinomialNB_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Compute the classification accuracy on the training data by either using the `accuracy_score` metric or the `score` method of the `MultinomialNB`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n",
    "MultinomialNB_model.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 7 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical log probability of input features given a class $P\\left(x_i  |  y\\right)$ is given by the feature `feature_log_prob` of the classifier. For each feature there are two such conditional probabilities, one for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** What dimensionality do you expect the `feature_log_prob_` array to have? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Student needs to answer similar to below:***\n",
    "\n",
    "There is a probability for each feature(/variable) conditional on each of the two outcome values, so the dimensionality should logically be (54,2) or (2,54)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Inspect the log probabilities of the features. Verify that it has the expected dimensionality (i.e. `shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Create a list of the names of the features that have higher log probability when the email is `Ham` than `Spam` i.e. what features imply an email is more likely to be `Ham`? *Hint:* There are a many ways to do this. Try it on your own then, if you get stuck, you can do it using index numbers (look up [`np.argwhere`](https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html)), or using a boolean mask (look up [pandas indexing](https://pandas.pydata.org/docs/user_guide/indexing.html)). The column names of a Pandas DataFrame are contained in the `columns` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 8 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final part of this section we will now pretend we are spammers wishing to fool a spam checking system based on NaÃ¯ve Bayes into classifying a spam e-mail as ham (i.e. a valid e-mail). For this we will use a test set consisting of just one data point (i.e. e-mail). This tiny dataset is called `spambase_test` and has already been pre-processed for you which means that the redundant features have been removed and word frequencies have been replaced by word presence/absence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Load `./datasets/spambase_test.csv` dataset into a new pandas structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Use `spambase_test` to create a pandas DataFrame object X_test, contatining the test features, and pandas Series object y_test, containing the test outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Feed the input features into the classifier and compare the outcome to the true label. Make sure you don't feed the target into the classifier as you will receive an error (why?). Does the classifer classify the spam e-mail correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Pick one (perhaps random) feature that has higher probability for the ham class (using your feature names from earlier) and set the corresponding value in `X_test` to 1. Now predict the new outcome. Has it changed? If not, keep modifying more features until you have achieved the desired outcome (i.e. model classifies the e-mail as ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 9 ==========\n",
    "We now train a [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) classifier and [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression.fit#sklearn.linear_model.LogisticRegression.fit) it by using the training data. Use the `lbfgs` solver and default settings for the other parameters. Report the classification accuracy on both the training (`X` and `y`) and test sets (`X_test` and `y_test`). Does your classifier generalise well on unseen data?\n",
    "(You can use the default [`score` method for `LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression.fit#sklearn.linear_model.LogisticRegression.score) to evaluate the classification accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Train the Logistic Regression binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Print the weight and bias of the binary Logistic Regression classifier (look up the Attributes of [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
